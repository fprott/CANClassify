{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train the LSTM model for CANClassify"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from main import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'velocity_x', # velocity in the forward direction\n",
    "    'acceleration_x', # acceleration in the forward direction\n",
    "    'acceleration_y', # acceleration in the horizontal direction\n",
    "    'steer_angle',\n",
    "    'steer_angle_rate',\n",
    "    'brake_pedal', # continuous value for how much it is pressed\n",
    "    'gas_pedal', # continuous value for how much it is pressed\n",
    "    'radar_long', # longitudinal\n",
    "    'radar_lat', # latitudinal\n",
    "    'radar_rel_vel', # relative velocity in the forward direction\n",
    "    'radar_rel_acc', # relative acceleration in the forward direction\n",
    "    'checksum',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open(\"data/data_x\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open(\"data/data_y\", \"rb\") as f:\n",
    "    Y = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make the network\n",
    "\n",
    "- Input layer of size 716 * 100\n",
    "- Layer of size 500\n",
    "- LSTM layer 200 (give sequence to next layer)\n",
    "- LSTM layer 200 (dropout 0.1 to ->)\n",
    "- Layer of size 100 (dropout 0.1 to ->)\n",
    "- Layer of size 50\n",
    "- Output layer (raw probabilities, no softmax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(285)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "temp = list(zip(X, Y))\n",
    "np.random.shuffle(temp)\n",
    "\n",
    "X, Y = zip(*temp)\n",
    "\n",
    "del temp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "split_index = int(len(X)*0.80)\n",
    "\n",
    "trainX = np.array(X[:split_index])\n",
    "testX = np.array(X[split_index:])\n",
    "\n",
    "trainy = np.array(Y[:split_index])\n",
    "testy = np.array(Y[split_index:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "assert Y[0].shape[0] == len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Only run training this once"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100, 500)          358500    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 256)          775168    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               25700     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                612       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,690,342\n",
      "Trainable params: 1,690,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features = X[0].shape\n",
    "n_outputs = Y[0].shape[0]\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(500, input_shape=(n_timesteps,n_features)))\n",
    "model.add(layers.LSTM(256, input_shape=(500,), return_sequences=True))\n",
    "model.add(layers.LSTM(256, input_shape=(500,)))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(100))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(50))\n",
    "\n",
    "\n",
    "# if using non softmax:\n",
    "# model.add(layers.Dense(n_outputs))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['MeanSquaredError'])\n",
    "\n",
    "# if using softmax\n",
    "# model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if using multiclass multilabel\n",
    "model.add(layers.Dense(n_outputs, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "907/907 [==============================] - 2246s 2s/step - loss: 0.2093 - accuracy: 0.4142\n",
      "Epoch 2/6\n",
      "907/907 [==============================] - 2267s 2s/step - loss: 0.1494 - accuracy: 0.6172\n",
      "Epoch 3/6\n",
      "907/907 [==============================] - 2243s 2s/step - loss: 0.1227 - accuracy: 0.7013\n",
      "Epoch 4/6\n",
      "907/907 [==============================] - 2174s 2s/step - loss: 0.0994 - accuracy: 0.7623\n",
      "Epoch 5/6\n",
      "907/907 [==============================] - 2118s 2s/step - loss: 0.0881 - accuracy: 0.7928\n",
      "Epoch 6/6\n",
      "907/907 [==============================] - 2102s 2s/step - loss: 0.0810 - accuracy: 0.8118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainy, epochs=6, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output/convolve_lstm_multilabel_model.tfsmf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output/convolve_lstm_multilabel_model.tfsmf\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002549CAC64C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000254882B8A60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(f'output/convolve_lstm_multilabel_model.tfsmf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}